# 3. Log Management Challenges
## 3.1 Good Log Data - Quality and Performance Factors
So let's have a quick look at how we can define good log data. We can identify three criteria in defining the quality and performance factors of data provided by log management: 
1- If there are missing logs or not, 
2- If logs are relevant, and
3- If the logs are delivered to SIEMs with no delay.

If you look at these briefly, 
- Firstly, the coverage should be comprehensive to ensure all required data from systems, security devices, and others are collected so that no critical events stay out of the SOC visibility.
- It is also important not to inflate the logging infrastructure with data that does not add good enough context. This would create complexity, performance issues, storage shortage, and unnecessarily taking away from the event per second (EPS) license capacity.
- Secondly, the level of detail logs contain is also very important. The SIEM may have received the log, but the event types and event attributes may be off to pinpoint an event. Or, conversely, logging maybe in the verbose level that contains unnecessary details. 
- Thirdly, the timing of a log delivery is a crucial factor in detecting incidents early on. Infrastructural issues or policy configurations may delay the log delivery.

So, to summarize, SIEM practitioners that are in charge of the log management needs to

- make sure that they strike the right balance on the number of sources they collect logs from. 
- logs should contain the required detail with no excess information, and
- logs are to be delivered and collected with no delay.

![image](https://user-images.githubusercontent.com/58542375/177359832-e50bd5ee-e495-430e-991e-c7c4566523c2.png)

## 3.2 Centralized Log Collection
Now I'd like to talk about log management challenges about having good data. As you guessed, it is not easy, and many factors create challenges for Effective log management and make good data available continuously. 
- Firstly, SIEMs need to collect logs from various data sources that may be located on-premises networks, collected in the data center, or in the cloud. Different platform characteristics and connectivity modes are prone to create log delivery and collection issues. 
- As another challenge, due to network interruptions,API related issues, and software bugs, configuration errors, log delivery may have stopped altogether from a particular network segment or endpontsystem. For example, SOC teams may not be aware of it.
- The last challenge is about the size of logs.Statistics are showing that in enterprise networks, log size can easily reach 10 terabytes each month. Collecting, storing, analyzing, and normalizing such big volumes also makes log management difficult.

![image](https://user-images.githubusercontent.com/58542375/177361144-5ed88e61-a14d-4f8e-975b-29d50d87423b.png)

## 3.3 Keeping up with the Changes
Continuing with the challenges, another important dimension is related to keeping up with internal and external changes. 
- At any time, a new machine, software, or network device can be turned on and start producing new log data, and it is not easily spotted the new log sources in the networks. 
- Cloud instances can be launched for a few days or hours and then get shut down.

So, SOC teams must be aware of architectural changes, new deployments, new applications, and retiring technologies to keep log management aligned with these changes that are handled by network operations, IT security, applications, teams, DevOps, and others. 

Changes in the adversarial landscape can also create blind spots in networks. New attack vectors and attack techniques may require that some log sources, event types, and attributes excluded before are to be included going forward. 

For example, attackers started obfuscating PowerShell commands to evade security controls and stay under the radar. Once this new TTP activity is identified, it has become necessary to collect logs from Windows Event ID 4104 to detect obfuscated PowerShell commands from now on. So logging should be updated to gain visibility on such new TTPs.

![image](https://user-images.githubusercontent.com/58542375/177362270-4ec87c69-3a1d-4dee-ab5d-7b8ab387d10e.png)

## 3.4 Normalization
And finally, on the challenges, the log data is diverse. Systems, applications, and network devices each have their logs containing different types of data, but a single log source may contain multiple logs. Applications, for example, often have several log files, each containing a different form of data. 

The contents of logs vary considerably.
- Some logs are constructed to be read by humans, while others aren't; some use standard formats, while others use proprietary ones. 
- Some log formats use commas to separate fields, others use spaces to separate fields within a single log message, and still, others use symbols or other character delimiters.  

Even if two sources record the same values, they may have different representations. 
- For example, a date may be formatted month month / day day / year year year year or day day / month month / year year year year. 
- For a human reviewer, parsing dates in different formats might be easy but considering an FTP session being recorded by one log source as "POP3" and another as "110", the default port number of the POP3 protocol.

So putting all these challenges together: the difficulty of collecting, keeping logs up-to-date, and normalizing a variety of formats tells us that things can quickly go wrong without SOC teams noticing and therefore validating the consistency of log infrastructure, coverage, adaptability needs to be part of the log management processes.

![image](https://user-images.githubusercontent.com/58542375/177362560-0c382d36-f956-427f-8774-adc54c3c94ae.png)

## 3.5 Log Security and Protection
The last challenge that I want to  mention is Log Security and Protection.

- First of all, you must ensure that the processes that produce log entries are secured. The integrity of log collectors, configuration files, and other components of log sources must be assured.
- You also need to secure log data transfer by using secure mechanisms such as encryption. 
- Confidentiality and integrity of log files in storage are also crucial. 
-You are required to protect physical logging infrastructure and prevent unauthorized access.
- Finally, you have to maintain business continuity.

![image](https://user-images.githubusercontent.com/58542375/177363036-26a71819-1fcc-4b77-b4c2-809630905561.png)

